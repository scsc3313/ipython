{
 "metadata": {
  "name": "",
  "signature": "sha256:f08e009200261bf74cea773fc0578bf6e7e611342c3ef8bce355de56e9392712"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Developing and Evaluating Chunkers"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Rule base Chunker"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text = '''\n",
      "... he PRP B-NP\n",
      "... accepted VBD B-VP\n",
      "... the DT B-NP\n",
      "... position NN I-NP\n",
      "... of IN B-PP\n",
      "... vice NN B-NP\n",
      "... chairman NN I-NP\n",
      "... of IN B-PP\n",
      "... Carlyle NNP B-NP\n",
      "... Group NNP I-NP\n",
      "... , , O\n",
      "... a DT B-NP\n",
      "... merchant NN I-NP\n",
      "... banking NN I-NP\n",
      "... concern NN I-NP\n",
      "... . . O\n",
      "... '''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "he PRP B-NP\n",
        "accepted VBD B-VP\n",
        "the DT B-NP\n",
        "position NN I-NP\n",
        "of IN B-PP\n",
        "vice NN B-NP\n",
        "chairman NN I-NP\n",
        "of IN B-PP\n",
        "Carlyle NNP B-NP\n",
        "Group NNP I-NP\n",
        ", , O\n",
        "a DT B-NP\n",
        "merchant NN I-NP\n",
        "banking NN I-NP\n",
        "concern NN I-NP\n",
        ". . O\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.chunk.conllstr2tree(text, chunk_types=['NP'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/lib/python2.7/site-packages/IPython/core/formatters.py:239: FormatterWarning: Exception in image/png formatter: no display name and no $DISPLAY environment variable\n",
        "  FormatterWarning,\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "Tree('S', [Tree('NP', [(u'he', u'PRP')]), (u'accepted', u'VBD'), Tree('NP', [(u'the', u'DT'), (u'position', u'NN')]), (u'of', u'IN'), Tree('NP', [(u'vice', u'NN'), (u'chairman', u'NN')]), (u'of', u'IN'), Tree('NP', [(u'Carlyle', u'NNP'), (u'Group', u'NNP')]), (u',', u','), Tree('NP', [(u'a', u'DT'), (u'merchant', u'NN'), (u'banking', u'NN'), (u'concern', u'NN')]), (u'.', u'.')])"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.chunk.conllstr2tree(text, chunk_types=['NP']).draw()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TclError",
       "evalue": "no display name and no $DISPLAY environment variable",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTclError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-5-4a4db0b39cdd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconllstr2tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'NP'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m/usr/lib/python2.7/site-packages/nltk/tree.pyc\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    684\u001b[0m         \"\"\"\n\u001b[0;32m    685\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdraw_trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m         \u001b[0mdraw_trees\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/site-packages/nltk/draw/tree.pyc\u001b[0m in \u001b[0;36mdraw_trees\u001b[1;34m(*trees)\u001b[0m\n\u001b[0;32m    864\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m     \"\"\"\n\u001b[1;32m--> 866\u001b[1;33m     \u001b[0mTreeView\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib/python2.7/site-packages/nltk/draw/tree.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *trees)\u001b[0m\n\u001b[0;32m    757\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trees\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrees\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_top\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_top\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'NLTK'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_top\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<Control-x>'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/lib64/python2.7/lib-tk/Tkinter.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[0;32m   1743\u001b[0m                 \u001b[0mbaseName\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbaseName\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mext\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m         \u001b[0minteractive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscreenName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbaseName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwantobjects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0museTk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msync\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1746\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0museTk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1747\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loadtk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mTclError\u001b[0m: no display name and no $DISPLAY environment variable"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import conll2000\n",
      "print(conll2000.chunked_sents('train.txt')[99])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(S\n",
        "  (PP Over/IN)\n",
        "  (NP a/DT cup/NN)\n",
        "  (PP of/IN)\n",
        "  (NP coffee/NN)\n",
        "  ,/,\n",
        "  (NP Mr./NNP Stone/NNP)\n",
        "  (VP told/VBD)\n",
        "  (NP his/PRP$ story/NN)\n",
        "  ./.)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Simple Evalution and Baselines"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import conll2000\n",
      "cp = nltk.RegexpParser(\"\")\n",
      "test_sents = conll2000.chunked_sents('test.txt', chunk_types=['NP'])\n",
      "print(cp.evaluate(test_sents))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ChunkParse score:\n",
        "    IOB Accuracy:  43.4%\n",
        "    Precision:      0.0%\n",
        "    Recall:         0.0%\n",
        "    F-Measure:      0.0%\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grammar = r\"NP: {<[CDJNP].*>+}\"\n",
      "cp = nltk.RegexpParser(grammar)\n",
      "print(cp.evaluate(test_sents))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ChunkParse score:\n",
        "    IOB Accuracy:  87.7%\n",
        "    Precision:     70.6%\n",
        "    Recall:        67.8%\n",
        "    F-Measure:     69.2%\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class UnigramChunker(nltk.ChunkParserI):\n",
      "    def __init__(self, train_sents):\n",
      "        train_data = [[(t,c) for w,t,c in nltk.chunk.tree2conlltags(sent)]\n",
      "                      for sent in train_sents]\n",
      "        self.tagger = nltk.UnigramTagger(train_data)\n",
      "\n",
      "    def parse(self, sentence):\n",
      "        pos_tags = [pos for (word,pos) in sentence]\n",
      "        tagged_pos_tags = self.tagger.tag(pos_tags)\n",
      "        chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]\n",
      "        conlltags = [(word, pos, chunktag) for ((word,pos),chunktag)\n",
      "                     in zip(sentence, chunktags)]\n",
      "        return nltk.chunk.conlltags2tree(conlltags)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "nltk.ChunkParserI \uc778\ud130\ud398\uc774\uc2a4\ub97c \uc0c1\uc18d\ubc1b\uc544\uc11c \uc720\ub2c8\uadf8\ub7a8 \uccad\ud06c\ub97c \uc791\uc131 "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "parse method : \uc785\ub825\uc73c\ub85c \ubb38\uc7a5\uc744 \uc785\ub825\ubc1b\uace0 \uccad\ud06c\ub97c \uc791\uc131\ud55c\ub2e4. \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_sents = conll2000.chunked_sents('test.txt', chunk_types=['NP'])\n",
      "train_sents = conll2000.chunked_sents('train.txt', chunk_types=['NP'])\n",
      "unigram_chunker = UnigramChunker(train_sents)\n",
      "print(unigram_chunker.evaluate(test_sents))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ChunkParse score:\n",
        "    IOB Accuracy:  92.9%\n",
        "    Precision:     79.9%\n",
        "    Recall:        86.8%\n",
        "    F-Measure:     83.2%\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "postags = sorted(set(pos for sent in train_sents for (word,pos) in sent.leaves()))\n",
      "print(unigram_chunker.tagger.tag(postags))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(u'#', u'B-NP'), (u'$', u'B-NP'), (u\"''\", u'O'), (u'(', u'O'), (u')', u'O'), (u',', u'O'), (u'.', u'O'), (u':', u'O'), (u'CC', u'O'), (u'CD', u'I-NP'), (u'DT', u'B-NP'), (u'EX', u'B-NP'), (u'FW', u'I-NP'), (u'IN', u'O'), (u'JJ', u'I-NP'), (u'JJR', u'B-NP'), (u'JJS', u'I-NP'), (u'MD', u'O'), (u'NN', u'I-NP'), (u'NNP', u'I-NP'), (u'NNPS', u'I-NP'), (u'NNS', u'I-NP'), (u'PDT', u'B-NP'), (u'POS', u'B-NP'), (u'PRP', u'B-NP'), (u'PRP$', u'B-NP'), (u'RB', u'O'), (u'RBR', u'O'), (u'RBS', u'B-NP'), (u'RP', u'O'), (u'SYM', u'O'), (u'TO', u'O'), (u'UH', u'O'), (u'VB', u'O'), (u'VBD', u'O'), (u'VBG', u'O'), (u'VBN', u'O'), (u'VBP', u'O'), (u'VBZ', u'O'), (u'WDT', u'B-NP'), (u'WP', u'B-NP'), (u'WP$', u'B-NP'), (u'WRB', u'O'), (u'``', u'O')]\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class BigramChunker(nltk.ChunkParserI):\n",
      "    def __init__(self, train_sents):\n",
      "        train_data = [[(t,c) for w,t,c in nltk.chunk.tree2conlltags(sent)]\n",
      "                      for sent in train_sents]\n",
      "        self.tagger = nltk.BigramTagger(train_data)\n",
      "\n",
      "    def parse(self, sentence):\n",
      "        pos_tags = [pos for (word,pos) in sentence]\n",
      "        tagged_pos_tags = self.tagger.tag(pos_tags)\n",
      "        chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]\n",
      "        conlltags = [(word, pos, chunktag) for ((word,pos),chunktag)\n",
      "                     in zip(sentence, chunktags)]\n",
      "        return nltk.chunk.conlltags2tree(conlltags)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigram_chunker = BigramChunker(train_sents)\n",
      "print(bigram_chunker.evaluate(test_sents))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ChunkParse score:\n",
        "    IOB Accuracy:  93.3%\n",
        "    Precision:     82.3%\n",
        "    Recall:        86.8%\n",
        "    F-Measure:     84.5%\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "3.3   Training Classifier-Based Chunkers"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "\uae30\uacc4\ud559\uc2b5 \uae30\ubc18\uc758 chunker"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "a.\t\tJoey/NN sold/VBD the/DT farmer/NN rice/NN ./.<br>\n",
      "b.\t\tNick/NN broke/VBD my/DT computer/NN monitor/NN ./."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\ub8f0 \uae30\ubc18 \uccad\ud06c\uc758 \uc57d\uc810<br>\n",
      "a. the farmer, rice<br>\n",
      "b. the computer monitor<br>\n",
      "a\uc640 b\ub294 \uac19\uc740 \ud488\uc0ac\uc758 \uc21c\uc11c\ub97c \uac00\uc9c0\uae30 \ub54c\ubb38\uc5d0 \ub8f0\uae30\ubc18 \uccad\ud06c\ub294 \uc704\uc640 \uac19\uc740 \uacb0\uacfc\ub97c \ub9cc\ub4e4\uc5b4 \ub0bc \uc218 \uc5c6\ub2e4. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Chunker\uc5d0\uc11c \uc0ac\uc6a9\ud558\ub294 \ud074\ub798\uc2dc\ud53c\ucf00\uc774\uc158 \ub77c\uc774\ube0c\ub7ec\ub9ac\ub294 meagam\uc774\ub77c\ub294 \ubcc4\ub3c4\uc758 \ub77c\uc774\ube0c\ub7ec\ub9ac\uc758 \uc124\uce58\ub97c \ud544\uc694.<br>\n",
      "ocaml\uc774\ub77c\ub294 \ucef4\ud30c\uc77c\ub7ec(http://caml.inria.fr/ocaml/release.en.html)<br>\n",
      "ocaml\uc744 \uae30\ubc18\uc73c\ub85c \ud558\ub294 megam(http://www.umiacs.umd.edu/~hal/megam/)\uc774\ub77c\ub294 \ud074\ub798\uc2dc\ud53c\ucf00\uc774\uc158 \ub77c\uc774\ube0c\ub7ec\ub9ac<br>\n",
      "ocaml\uc740 \ubc30\ud3ec\ud310 \uc124\uce58\ud6c4 ./configure && make world.opt &&\tmake install \uacfc\uc815\uc744 \ud1b5\ud574 \uc124\uce58<br>\n",
      "megam\uc740 \uc18c\uc2a4\ucf54\ub4dc \ub2e4\uc6b4 \ub85c\ub4dc\ud6c4 \ucf54\ub4dc \uc218\uc815 \ubc0f make file \uc218\uc815 \ud544\uc694<br>\n",
      "\uc18c\uc2a4\ucf54\ub4dc \uc218\uc815 : fastdot_c.c \uc218\uc815 <br>\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#include <stddef.h>\n",
      "#include <stdarg.h>\n",
      "#include <string.h>\n",
      "#include \"alloc.h\"    -> <caml/alloc.h>\n",
      "#include \"bigarray.h\" -> <caml/bigarray.h>\n",
      "#include \"custom.h\"   -> <caml/custom.h>\n",
      "#include \"fail.h\"     -> <caml/fail.h>\n",
      "#include \"intext.h\"   -> <caml/intext.h>\n",
      "#include \"memory.h\"   -> <caml/memoty.h>\n",
      "#include \"mlvalues.h\" -> <caml/mlvalues.h>\n",
      "#include \"math.h\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Makefile \uc218\uc815 <br>\n",
      "62\ubc88\uc9f8 \ub77c\uc778 -lstr -> -lcamlstr "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "NLTK\uc5d0\uc11c \ud574\ub2f9 \ub77c\uc774\ube0c\ub7ec\ub9ac \uc0ac\uc6a9\ud558\uae30\uc804 megam \uacbd\ub85c \uc124\uc815.<br>\n",
      "nltk.config_megam('\uacbd\ub85c')"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\ucf54\ub4dc\ub97c \uc2e4\ud589 \uc2dc\ud0a4\uae30 \uc804\uc5d0 \ud074\ub798\uc2dc\ud53c\ucf00\uc774\uc158 \ub77c\uc774\ube0c\ub7ec\ub9ac\ub97c \uc124\uc815\ud55c\ub2e4.\n",
      "nltk.config_megam('/home/dev/megam/megam_0.92/megam')\n",
      "\n",
      "class ConsecutiveNPChunkTagger(nltk.TaggerI):\n",
      "    def __init__(self, train_sents):\n",
      "        train_set = []\n",
      "        for tagged_sent in train_sents:\n",
      "            untagged_sent = nltk.tag.untag(tagged_sent)\n",
      "            history = []\n",
      "            for i, (word, tag) in enumerate(tagged_sent):\n",
      "                featureset = npchunk_features(untagged_sent, i, history)\n",
      "                train_set.append( (featureset, tag) )\n",
      "                history.append(tag)\n",
      "        self.classifier = nltk.MaxentClassifier.train(\n",
      "            train_set, algorithm='megam', trace=0)\n",
      "\n",
      "    def tag(self, sentence):\n",
      "        history = []\n",
      "        for i, word in enumerate(sentence):\n",
      "            featureset = npchunk_features(sentence, i, history)\n",
      "            tag = self.classifier.classify(featureset)\n",
      "            history.append(tag)\n",
      "        return zip(sentence, history)\n",
      "\n",
      "class ConsecutiveNPChunker(nltk.ChunkParserI):\n",
      "    def __init__(self, train_sents):\n",
      "        tagged_sents = [[((w,t),c) for (w,t,c) in\n",
      "                         nltk.chunk.tree2conlltags(sent)]\n",
      "                        for sent in train_sents]\n",
      "        self.tagger = ConsecutiveNPChunkTagger(tagged_sents)\n",
      "\n",
      "    def parse(self, sentence):\n",
      "        tagged_sents = self.tagger.tag(sentence)\n",
      "        conlltags = [(w,t,c) for ((w,t),c) in tagged_sents]\n",
      "        return nltk.chunk.conlltags2tree(conlltags)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Found /home/dev/megam/megam_0.92/megam: /home/dev/megam/megam_0.92/megam]\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "unigram npChunk"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def npchunk_features(sentence, i, history):\n",
      "    word, pos = sentence[i]\n",
      "    return {\"pos\": pos}\n",
      "chunker = ConsecutiveNPChunker(train_sents)\n",
      "print(chunker.evaluate(test_sents))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ChunkParse score:\n",
        "    IOB Accuracy:  92.9%\n",
        "    Precision:     79.9%\n",
        "    Recall:        86.7%\n",
        "    F-Measure:     83.2%\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "bigram npChunk"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def npchunk_features(sentence, i, history):     \n",
      "    word, pos = sentence[i]\n",
      "    if i == 0:\n",
      "        prevword, prevpos = \"<START>\", \"<START>\"\n",
      "    else:\n",
      "        prevword, prevpos = sentence[i-1]\n",
      "    return {\"pos\": pos, \"prevpos\": prevpos}\n",
      "chunker = ConsecutiveNPChunker(train_sents)\n",
      "print(chunker.evaluate(test_sents))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ChunkParse score:\n",
        "    IOB Accuracy:  93.6%\n",
        "    Precision:     82.0%\n",
        "    Recall:        87.1%\n",
        "    F-Measure:     84.5%\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "bigram npChunk\uc5d0 \ud604\uc7ac \uc0c1\ud0dc\ub97c \ucd94\uac00. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def npchunk_features(sentence, i, history):\n",
      "    word, pos = sentence[i]\n",
      "    if i == 0:\n",
      "        prevword, prevpos = \"<START>\", \"<START>\"\n",
      "    else:\n",
      "        prevword, prevpos = sentence[i-1]\n",
      "    return {\"pos\": pos, \"word\": word, \"prevpos\": prevpos}\n",
      "chunker = ConsecutiveNPChunker(train_sents)\n",
      "print(chunker.evaluate(test_sents))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ChunkParse score:\n",
        "    IOB Accuracy:  94.3%\n",
        "    Precision:     83.7%\n",
        "    Recall:        88.7%\n",
        "    F-Measure:     86.2%\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\uc880 \ub354 \ubcf5\uc7a1\ud55c npChunk"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\ud604\uc7ac \ub2e8\uc5b4, \ud604\uc7ac \ud488\uc0ac, \uc774\uc804 \ud488\uc0ac, \uc774\uc804 \ub2e8\uc5b4, \ub2e4\uc74c \ub2e8\uc5b4, \ub2e4\uc74c \ud488\uc0ac, \uad00\uc0ac\ub85c\ubd80\ud130 \uc704\uce58 "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def npchunk_features(sentence, i, history):\n",
      "    word, pos = sentence[i]\n",
      "    if i == 0:\n",
      "        prevword, prevpos = \"<START>\", \"<START>\"\n",
      "    else:\n",
      "        prevword, prevpos = sentence[i-1]\n",
      "    if i == len(sentence)-1:\n",
      "        nextword, nextpos = \"<END>\", \"<END>\"\n",
      "    else:\n",
      "        nextword, nextpos = sentence[i+1]\n",
      "    return {\"pos\": pos,\n",
      "            \"word\": word,\n",
      "            \"prevpos\": prevpos,\n",
      "            \"nextpos\": nextpos,\n",
      "            \"prevpos+pos\": \"%s+%s\" % (prevpos, pos),\n",
      "            \"pos+nextpos\": \"%s+%s\" % (pos, nextpos),\n",
      "            \"tags-since-dt\": tags_since_dt(sentence, i)}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tags_since_dt(sentence, i):\n",
      "    tags = set()\n",
      "    for word, pos in sentence[:i]:\n",
      "        if pos == 'DT':\n",
      "            tags = set()\n",
      "        else:\n",
      "            tags.add(pos)\n",
      "    return '+'.join(sorted(tags))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chunker = ConsecutiveNPChunker(train_sents)\n",
      "print(chunker.evaluate(test_sents))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ChunkParse score:\n",
        "    IOB Accuracy:  96.0%\n",
        "    Precision:     88.6%\n",
        "    Recall:        91.0%\n",
        "    F-Measure:     89.8%\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "4. Recursion in Linguistic Structure"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "skip"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "5. Name Entity Recognition"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\ud55c\uad6d\uc5b4 \uac1c\uccb4\uba85 \uc778\uc2dd<br>\n",
      "http://swguru.kr/48"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The goal of a named entity recognition (NER) system is to identify all textual mentions of the named entities. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "example of NE"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=ne.png>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "IOB format\uc744 \uc774\uc6a9\ud574\uc11c \uac1c\ucc44\uba85\uc744 \ucd94\ucd9c"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sent = nltk.corpus.treebank.tagged_sents()[22]\n",
      "print(nltk.ne_chunk(sent, binary=True))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(S\n",
        "  The/DT\n",
        "  (NE U.S./NNP)\n",
        "  is/VBZ\n",
        "  one/CD\n",
        "  of/IN\n",
        "  the/DT\n",
        "  few/JJ\n",
        "  industrialized/VBN\n",
        "  nations/NNS\n",
        "  that/WDT\n",
        "  *T*-7/-NONE-\n",
        "  does/VBZ\n",
        "  n't/RB\n",
        "  have/VB\n",
        "  a/DT\n",
        "  higher/JJR\n",
        "  standard/NN\n",
        "  of/IN\n",
        "  regulation/NN\n",
        "  for/IN\n",
        "  the/DT\n",
        "  smooth/JJ\n",
        "  ,/,\n",
        "  needle-like/JJ\n",
        "  fibers/NNS\n",
        "  such/JJ\n",
        "  as/IN\n",
        "  crocidolite/NN\n",
        "  that/WDT\n",
        "  *T*-1/-NONE-\n",
        "  are/VBP\n",
        "  classified/VBN\n",
        "  *-5/-NONE-\n",
        "  as/IN\n",
        "  amphobiles/NNS\n",
        "  ,/,\n",
        "  according/VBG\n",
        "  to/TO\n",
        "  (NE Brooke/NNP)\n",
        "  T./NNP\n",
        "  Mossman/NNP\n",
        "  ,/,\n",
        "  a/DT\n",
        "  professor/NN\n",
        "  of/IN\n",
        "  pathlogy/NN\n",
        "  at/IN\n",
        "  the/DT\n",
        "  (NE University/NNP)\n",
        "  of/IN\n",
        "  (NE Vermont/NNP College/NNP)\n",
        "  of/IN\n",
        "  (NE Medicine/NNP)\n",
        "  ./.)\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(nltk.ne_chunk(sent)) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(S\n",
        "  The/DT\n",
        "  (GPE U.S./NNP)\n",
        "  is/VBZ\n",
        "  one/CD\n",
        "  of/IN\n",
        "  the/DT\n",
        "  few/JJ\n",
        "  industrialized/VBN\n",
        "  nations/NNS\n",
        "  that/WDT\n",
        "  *T*-7/-NONE-\n",
        "  does/VBZ\n",
        "  n't/RB\n",
        "  have/VB\n",
        "  a/DT\n",
        "  higher/JJR\n",
        "  standard/NN\n",
        "  of/IN\n",
        "  regulation/NN\n",
        "  for/IN\n",
        "  the/DT\n",
        "  smooth/JJ\n",
        "  ,/,\n",
        "  needle-like/JJ\n",
        "  fibers/NNS\n",
        "  such/JJ\n",
        "  as/IN\n",
        "  crocidolite/NN\n",
        "  that/WDT\n",
        "  *T*-1/-NONE-\n",
        "  are/VBP\n",
        "  classified/VBN\n",
        "  *-5/-NONE-\n",
        "  as/IN\n",
        "  amphobiles/NNS\n",
        "  ,/,\n",
        "  according/VBG\n",
        "  to/TO\n",
        "  (PERSON Brooke/NNP T./NNP Mossman/NNP)\n",
        "  ,/,\n",
        "  a/DT\n",
        "  professor/NN\n",
        "  of/IN\n",
        "  pathlogy/NN\n",
        "  at/IN\n",
        "  the/DT\n",
        "  (ORGANIZATION University/NNP)\n",
        "  of/IN\n",
        "  (PERSON Vermont/NNP College/NNP)\n",
        "  of/IN\n",
        "  (GPE Medicine/NNP)\n",
        "  ./.)\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "6. Relation Extraction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\uad00\uacc4\ucd94\ucd9c"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\uad00\uacc4 : \uc758\ubbf8\uad00\uacc4, \uc0c1\ud558\uc704 \uad00\uacc4\ub4f1 \ubaa8\ub4e0 \uc885\ub958\uc758 \uad00\uacc4 "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "IN = re.compile(r'.*\\bin\\b(?!\\b.+ing)')\n",
      "for doc in nltk.corpus.ieer.parsed_docs('NYT_19980315'):\n",
      "    for rel in nltk.sem.extract_rels('ORG', 'LOC', doc, corpus='ieer', pattern = IN):\n",
      "        print(nltk.sem.rtuple(rel))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ORG: u'WHYY'] u'in' [LOC: u'Philadelphia']\n",
        "[ORG: u'McGlashan &AMP; Sarrail'] u'firm in' [LOC: u'San Mateo']\n",
        "[ORG: u'Freedom Forum'] u'in' [LOC: u'Arlington']\n",
        "[ORG: u'Brookings Institution'] u', the research group in' [LOC: u'Washington']\n",
        "[ORG: u'Idealab'] u', a self-described business incubator based in' [LOC: u'Los Angeles']\n",
        "[ORG: u'Open Text'] u', based in' [LOC: u'Waterloo']\n",
        "[ORG: u'WGBH'] u'in' [LOC: u'Boston']\n",
        "[ORG: u'Bastille Opera'] u'in' [LOC: u'Paris']\n",
        "[ORG: u'Omnicom'] u'in' [LOC: u'New York']\n",
        "[ORG: u'DDB Needham'] u'in' [LOC: u'New York']\n",
        "[ORG: u'Kaplan Thaler Group'] u'in' [LOC: u'New York']\n",
        "[ORG: u'BBDO South'] u'in' [LOC: u'Atlanta']\n",
        "[ORG: u'Georgia-Pacific'] u'in' [LOC: u'Atlanta']\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import conll2002\n",
      "vnv = \"\"\"\n",
      "    (\n",
      "    is/V|    # 3rd sing present and\n",
      "    was/V|   # past forms of the verb zijn ('be')\n",
      "    werd/V|  # and also present\n",
      "    wordt/V  # past of worden ('become)\n",
      "    )\n",
      "    .*       # followed by anything\n",
      "    van/Prep # followed by van ('of')\n",
      "    \"\"\"\n",
      "VAN = re.compile(vnv, re.VERBOSE)\n",
      "for doc in conll2002.chunked_sents('ned.train'):\n",
      "    for r in nltk.sem.extract_rels('PER', 'ORG', doc, corpus='conll2002', pattern=VAN):\n",
      "        print(nltk.sem.clause(r, relsym=\"VAN\"))\n",
      " "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "VAN(u\"cornet_d'elzius\", u'buitenlandse_handel')\n",
        "VAN(u'johan_rottiers', u'kardinaal_van_roey_instituut')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "VAN(u'annie_lennox', u'eurythmics')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 33
    }
   ],
   "metadata": {}
  }
 ]
}